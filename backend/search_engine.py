import faiss
import json
import numpy as np
from PIL import Image
import os
import cv2
import base64
import io

from .models import FeatureExtractor, LocalFeatureExtractor
from .video_processor import get_frame_from_video

class SearchEngine:
    def __init__(self, index_path='index.faiss', mapping_path='index_mapping.json'):
        self.base_dir = os.path.dirname(__file__)
        self.index_path = os.path.join(self.base_dir, index_path)
        self.mapping_path = os.path.join(self.base_dir, mapping_path)

        self.global_feature_extractor = FeatureExtractor()
        self.local_feature_extractor = LocalFeatureExtractor()
        
        self.index = None
        self.mapping = None

        if os.path.exists(self.index_path) and os.path.exists(self.mapping_path):
            print("ðŸ’¾ ê¸°ì¡´ ì¸ë±ìŠ¤ì™€ ë§¤í•‘ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.")
            self.index = faiss.read_index(self.index_path)
            with open(self.mapping_path, 'r', encoding='utf-8') as f:
                self.mapping = json.load(f)
            print("âœ… ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ.")
        else:
            print("âš ï¸ ê²½ê³ : ì¸ë±ìŠ¤ íŒŒì¼ ë˜ëŠ” ë§¤í•‘ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. '/index' APIë¥¼ ë¨¼ì € í˜¸ì¶œí•´ì£¼ì„¸ìš”.")

    # --- [ACCURACY-UP] í›„ë³´êµ°(candidates) ê¸°ë³¸ê°’ì„ 50ìœ¼ë¡œ ë³µì› ---
    def search(self, query_image: Image.Image, top_n: int = 5, candidates: int = 50, min_match_count: int = 10):
        if self.index is None or self.mapping is None:
            raise RuntimeError("ì¸ë±ìŠ¤ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € /index ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ ì¸ë±ì‹±ì„ ìˆ˜í–‰í•˜ì„¸ìš”.")

        # 1ë‹¨ê³„: FAISSë¡œ í›„ë³´êµ° íƒìƒ‰
        query_embedding = self.global_feature_extractor.get_embedding(query_image)
        query_vector = np.array([query_embedding]).astype('float32')
        distances, indices = self.index.search(query_vector, candidates)

        if not indices.size:
            return None

        # 2ë‹¨ê³„: ë¡œì»¬ íŠ¹ì§•ì  ë§¤ì¹­ìœ¼ë¡œ ìµœì¢… í”„ë ˆìž„ ê²°ì •
        query_kp, query_des = self.local_feature_extractor.get_features(query_image)
        if query_des is None:
            return None

        all_matches = []
        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

        for candidate_id in indices[0]:
            candidate_info = self.mapping[candidate_id]
            video_file = candidate_info["id"]
            timestamp = candidate_info["timestamp"]

            candidate_frame_pil = get_frame_from_video(video_file, timestamp)
            if candidate_frame_pil is None: continue

            frame_kp, frame_des = self.local_feature_extractor.get_features(candidate_frame_pil)
            if frame_des is None: continue

            matches = bf.match(query_des, frame_des)
            
            if len(matches) > min_match_count:
                all_matches.append({
                    "score": len(matches),
                    "video_file": video_file,
                    "timestamp": timestamp,
                    "matched_frame_pil": candidate_frame_pil
                })

        if not all_matches:
            return None

        sorted_matches = sorted(all_matches, key=lambda x: x['score'], reverse=True)
        top_results = sorted_matches[:top_n]

        final_results = []
        for result in top_results:
            buffered = io.BytesIO()
            result["matched_frame_pil"].save(buffered, format="JPEG")
            img_str = base64.b64encode(buffered.getvalue()).decode()
            
            final_results.append({
                "video_file": result["video_file"],
                "timestamp": result["timestamp"],
                "score": result["score"],
                "matched_frame": "data:image/jpeg;base64," + img_str,
            })

        return final_results